{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.6)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (4.34.1)\n",
      "Requirement already satisfied: tensorboard in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.1)\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: opencv-python in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: array-record in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (1.5.2)\n",
      "Requirement already satisfied: promise in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (5.9.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: toml in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: importlib_resources in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: zipp in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: backcall in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.61.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "git-lfs/3.4.0 (GitHub; darwin arm64; go 1.20.6)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datasets transformers tensorboard tensorflow ipywidgets opencv-python tensorflow-datasets\n",
    "!git-lfs --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to huggingface if first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73971dc964e842baa8cdcc490a4af22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the GPU is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config.experimental import list_physical_devices\n",
    "print(list_physical_devices('GPU'))\n",
    "\n",
    "model_id = \"google/vit-base-patch16-224-in21k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the database, also this is the time to define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4f8425242146ae9bccd44f4bc6fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_id)\n",
    "def transform(batch):\n",
    "    inputs = image_processor([x for x in batch[\"image\"]], return_tensors=\"tf\")\n",
    "    inputs[\"labels\"] = batch[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "dataset = load_dataset(\"streetview_images_cropped\", data_dir=\"./\")\n",
    "dataset = dataset.with_transform(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 36184\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 6386\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test size will be 15% of train dataset\n",
    "test_size=.15\n",
    "\n",
    "processed_dataset = dataset['train'].shuffle().train_test_split(test_size=test_size)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "class_labels = processed_dataset['train'].features[\"label\"].names\n",
    "num_images_train = processed_dataset['train'].num_rows\n",
    "id2label = {str(i): label for i, label in enumerate(class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 20\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 6e-5\n",
    "weight_decay_rate=0.01\n",
    "num_warmup_steps=0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "hub_token = HfFolder.get_token()\n",
    "hub_model_id = f'dl-au-tamas-jedrek/{model_id.split(\"/\")[1]}-street-view'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.12150204, 2.10150743, ..., 1.43083091, 2.64981238,\n",
       "        1.05595098],\n",
       "       [2.12150204, 0.        , 0.0631969 , ..., 0.7217327 , 2.86360224,\n",
       "        2.20667979],\n",
       "       [2.10150743, 0.0631969 , 0.        , ..., 0.68933549, 2.90697122,\n",
       "        2.21733372],\n",
       "       ...,\n",
       "       [1.43083091, 0.7217327 , 0.68933549, ..., 0.        , 2.77736714,\n",
       "        1.73784865],\n",
       "       [2.64981238, 2.86360224, 2.90697122, ..., 2.77736714, 0.        ,\n",
       "        1.60919535],\n",
       "       [1.05595098, 2.20667979, 2.21733372, ..., 1.73784865, 1.60919535,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/distances.json\", \"r\") as infile:\n",
    "    distances = json.load(infile)\n",
    "\n",
    "#make matrix with label2id\n",
    "import numpy as np\n",
    "mat_distances = np.zeros((len(label2id), len(label2id)))\n",
    "for key in distances.keys():\n",
    "    for key2 in distances[key].keys():\n",
    "        mat_distances[int(label2id[key])][int(label2id[key2])] = distances[key][key2]\n",
    "mat_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model, specify loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 10:39:35.861329: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2023-11-19 10:39:35.861355: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-19 10:39:35.861364: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-19 10:39:35.861767: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-19 10:39:35.862106: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some layers from the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing TFViTForImageClassification: ['vit/pooler/dense/bias:0', 'vit/pooler/dense/kernel:0']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_vi_t_for_image_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vit (TFViTMainLayer)        multiple                  85798656  \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  99201     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85897857 (327.67 MB)\n",
      "Trainable params: 85897857 (327.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = num_images_train * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# load pre-trained ViT model\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(class_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tensor_distances = tf.convert_to_tensor(mat_distances, dtype=tf.float32)\n",
    "def customLoss(y_true, y_pred):\n",
    "    y_pred_label = tf.argmax(y_pred, axis=1)\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    indices = tf.stack((y_true, y_pred_label), axis=1)\n",
    "    dist = tf.gather_nd(tensor_distances, indices)\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True) + (2 * dist)\n",
    "# define loss\n",
    "#loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss = customLoss\n",
    "\n",
    "# define metrics \n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vit.embeddings.trainable = True\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(processed_dataset['train'], batch_size=train_batch_size, shuffle=True)\n",
    "tf_eval_dataset = model.prepare_tf_dataset(processed_dataset['test'], batch_size=eval_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push metrics to hub after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au724747/projects/dl-geolocation-vit/vit-base-patch16-224-in21k is already a clone of https://huggingface.co/dl-au-tamas-jedrek/vit-base-patch16-224-in21k-street-view. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir, \"logs\")))\n",
    "#callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=1))\n",
    "callbacks.append(PushToHubCallback(\n",
    "    output_dir,\n",
    "    hub_model_id=hub_model_id,\n",
    "    hub_token=hub_token,\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 10:39:45.005106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130/1130 [==============================] - ETA: 0s - loss: 7.3925 - accuracy: 0.0770 - top-3-accuracy: 0.1607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in vit-base-patch16-224-in21k/config.json\n",
      "Model weights saved in vit-base-patch16-224-in21k/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130/1130 [==============================] - 3265s 3s/step - loss: 7.3925 - accuracy: 0.0770 - top-3-accuracy: 0.1607 - val_loss: 6.5825 - val_accuracy: 0.1311 - val_top-3-accuracy: 0.2495\n",
      "Epoch 2/20\n",
      "   9/1130 [..............................] - ETA: 51:57 - loss: 5.8923 - accuracy: 0.1667 - top-3-accuracy: 0.3056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m logging \u001b[39mas\u001b[39;00m transformers_logging\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m transformers_logging\u001b[39m.\u001b[39mset_verbosity_info()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     tf_train_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtf_eval_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/au724747/projects/dl-geolocation-vit/image-classification.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_info()\n",
    "train_results = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=num_train_epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "ec1370a512a4612a2908be3c3c8b0de1730d00dc30104daff827065aeaf438b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
