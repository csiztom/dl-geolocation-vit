{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.6)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (4.34.1)\n",
      "Requirement already satisfied: tensorboard in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.1)\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (2.14.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: backcall in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datasets transformers tensorboard tensorflow ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1c5234a03d49e2994a38250fb35490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "model_id = \"google/vit-base-patch16-224-in21k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "\n",
    "def create_image_folder_dataset(root_path):\n",
    "  \"\"\"creates `Dataset` from image folder structure\"\"\"\n",
    "  \n",
    "  # get class names by folders names\n",
    "  _CLASS_NAMES= os.listdir(root_path)\n",
    "  # defines `datasets` features`\n",
    "  features=datasets.Features({\n",
    "                      \"img\": datasets.Image(),\n",
    "                      \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "                  })\n",
    "  # temp list holding datapoints for creation\n",
    "  img_data_files=[]\n",
    "  label_data_files=[]\n",
    "  # load images into list for creation\n",
    "  for img_class in os.listdir(root_path):\n",
    "    for img in os.listdir(os.path.join(root_path,img_class)):\n",
    "      path_=os.path.join(root_path,img_class,img)\n",
    "      img_data_files.append(path_)\n",
    "      label_data_files.append(img_class)\n",
    "  # create dataset\n",
    "  ds = datasets.Dataset.from_dict({\"img\":img_data_files,\"label\":label_data_files},features=features)\n",
    "  return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = create_image_folder_dataset(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esbjerg Kommune',\n",
       " 'Horsens Kommune',\n",
       " 'Slagelse Kommune',\n",
       " 'Roskilde Kommune',\n",
       " 'Randers Kommune',\n",
       " 'Gentofte Kommune',\n",
       " 'Kolding Kommune',\n",
       " 'Gladsaxe Kommune',\n",
       " 'Silkeborg Kommune',\n",
       " 'Kalundborg Kommune']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_class_labels = raw_dataset.features[\"label\"].names\n",
    "img_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "2023-10-29 15:38:54.420559: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2023-10-29 15:38:54.420587: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-29 15:38:54.420594: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-29 15:38:54.420846: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-29 15:38:54.420875: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "# learn more about data augmentation here: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(feature_extractor.size, feature_extractor.size),\n",
    "        layers.Rescaling(1./255)\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# use keras image data augementation processing\n",
    "def augmentation(examples):\n",
    "    # print(examples[\"img\"])\n",
    "    examples[\"pixel_values\"] = [data_augmentation(image) for image in examples[\"img\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "# basic processing (only resizing)\n",
    "def process(examples):\n",
    "    examples.update(feature_extractor(examples['img'], ))\n",
    "    return examples\n",
    "\n",
    "# we are also renaming our label col to labels to use `.to_tf_dataset` later\n",
    "raw_dataset = raw_dataset.rename_column(\"label\", \"labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38987927f2b4b59a3d538a0d039f2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'labels', 'pixel_values'],\n",
       "    num_rows: 2802\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = raw_dataset.map(process, batched=True)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['img', 'labels', 'pixel_values'],\n",
       "        num_rows: 2381\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['img', 'labels', 'pixel_values'],\n",
       "        num_rows: 421\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test size will be 15% of train dataset\n",
    "test_size=.15\n",
    "\n",
    "processed_dataset = processed_dataset.shuffle().train_test_split(test_size=test_size)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(img_class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 5\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 6e-5\n",
    "weight_decay_rate=0.01\n",
    "num_warmup_steps=0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "hub_token = HfFolder.get_token()\n",
    "hub_model_id = f'{model_id.split(\"/\")[1]}-street-view'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.9/site-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = processed_dataset[\"train\"].to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=train_batch_size,\n",
    "   collate_fn=data_collator)\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = processed_dataset[\"test\"].to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=eval_batch_size,\n",
    "   collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing TFViTForImageClassification: ['vit/pooler/dense/kernel:0', 'vit/pooler/dense/bias:0']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# load pre-trained ViT model\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(img_class_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# define loss\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# define metrics \n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "]\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "\n",
    "callbacks=[]\n",
    "\n",
    "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir,\"logs\")))\n",
    "callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=1))\n",
    "if hub_token:\n",
    "  callbacks.append(PushToHubCallback(output_dir=output_dir,\n",
    "                                     hub_model_id=hub_model_id,\n",
    "                                     hub_token=hub_token))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 15:39:48.232950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 248s 3s/step - loss: 2.2467 - accuracy: 0.1810 - top-3-accuracy: 0.4259 - val_loss: 2.1715 - val_accuracy: 0.2399 - val_top-3-accuracy: 0.5107\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 228s 3s/step - loss: 2.0007 - accuracy: 0.3650 - top-3-accuracy: 0.6779 - val_loss: 2.0300 - val_accuracy: 0.3254 - val_top-3-accuracy: 0.6152\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 223s 3s/step - loss: 1.6910 - accuracy: 0.5745 - top-3-accuracy: 0.8480 - val_loss: 1.9131 - val_accuracy: 0.3610 - val_top-3-accuracy: 0.6770\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 483s 6s/step - loss: 1.3778 - accuracy: 0.7467 - top-3-accuracy: 0.9412 - val_loss: 1.8832 - val_accuracy: 0.3587 - val_top-3-accuracy: 0.6603\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 7293s 99s/step - loss: 1.1652 - accuracy: 0.8618 - top-3-accuracy: 0.9756 - val_loss: 1.8605 - val_accuracy: 0.3682 - val_top-3-accuracy: 0.6675\n"
     ]
    }
   ],
   "source": [
    "train_results = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_train_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/dl-au-tamas-jedrek/vit-base-patch16-224-in21k-street-view/blob/main/preprocessor_config.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "user = api.whoami(\"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\")\n",
    "\n",
    "\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "\n",
    "api.upload_file(\n",
    "    token=\"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\",\n",
    "    repo_id=f\"dl-au-tamas-jedrek/{hub_model_id}\",\n",
    "    path_or_fileobj=os.path.join(output_dir,\"preprocessor_config.json\"),\n",
    "    path_in_repo=\"preprocessor_config.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "ec1370a512a4612a2908be3c3c8b0de1730d00dc30104daff827065aeaf438b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
