{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install keras_cv datasets transformers tensorboard tensorflow ipywidgets opencv-python tensorflow-datasets\n",
    "!git-lfs --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to huggingface if first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the GPU is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.config.experimental import list_physical_devices\n",
    "print(list_physical_devices('GPU'))\n",
    "\n",
    "model_id = \"google/vit-base-patch16-224-in21k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the database, also this is the time to define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "from datasets import load_dataset\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_cv.layers import RandAugment\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model ID and other parameters\n",
    "num_layers = 2\n",
    "magnitude = 0.15\n",
    "\n",
    "# Load the ViTImageProcessor\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create RandAugment transformation\n",
    "rand_augment = RandAugment(\n",
    "    value_range=[0,1],\n",
    "    augmentations_per_image=num_layers,\n",
    "    magnitude=magnitude,\n",
    ")\n",
    "\n",
    "\n",
    "def transform(batch):\n",
    "    inputs = image_processor([x for x in batch[\"image\"]], return_tensors=\"tf\")\n",
    "    inputs[\"labels\"] = batch[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "def augment(batch):\n",
    "    inputs = image_processor([x for x in batch[\"image\"]], return_tensors=\"tf\")\n",
    "    transposed = tf.transpose(inputs[\"pixel_values\"], perm=[0,3,2,1])\n",
    "    augmented = rand_augment(transposed)\n",
    "    inputs[\"pixel_values\"] = tf.transpose(augmented, perm=[0,3,2,1])\n",
    "    inputs[\"labels\"] = batch[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "dataset = load_dataset(\"streetview_images_cropped\", data_dir=\"./\")\n",
    "\n",
    "test_size=.15\n",
    "\n",
    "dataset = dataset[\"train\"].shuffle().train_test_split(test_size=test_size)\n",
    "\n",
    "dataset['train'] = dataset['train'].with_transform(augment)\n",
    "dataset['test'] = dataset['test'].with_transform(transform)\n",
    "processed_dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "class_labels = processed_dataset['train'].features[\"label\"].names\n",
    "num_images_train = processed_dataset['train'].num_rows\n",
    "id2label = {str(i): label for i, label in enumerate(class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 10\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 6e-5\n",
    "weight_decay_rate=0.01\n",
    "num_warmup_steps=0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "hub_token = HfFolder.get_token()\n",
    "hub_model_id = f'dl-au-tamas-jedrek/{model_id.split(\"/\")[1]}-street-view'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model, specify loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = num_images_train * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# load pre-trained ViT model\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(class_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# define loss\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# define metrics \n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "]\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(processed_dataset['train'], batch_size=train_batch_size, shuffle=True)\n",
    "tf_eval_dataset = model.prepare_tf_dataset(processed_dataset['test'], batch_size=eval_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to display train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_images, sample_labels = next(iter(tf_train_dataset))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    transposed = tf.transpose(image)\n",
    "    plt.imshow(transposed.numpy())\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push metrics to hub after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir, \"logs\")))\n",
    "callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=1))\n",
    "callbacks.append(PushToHubCallback(\n",
    "    output_dir,\n",
    "    hub_model_id=hub_model_id,\n",
    "    hub_token=hub_token,\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_info()\n",
    "train_results = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=num_train_epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "ec1370a512a4612a2908be3c3c8b0de1730d00dc30104daff827065aeaf438b7"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
